{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6.2\">Extractive Question-Answering using BERT</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question Answering with BERT (Bidirectional Encoder Representations from Transformers) has revolutionized natural language understanding and information retrieval. BERT, a state-of-the-art transformer-based model, excels at capturing contextual relationships in text due to its bidirectional attention mechanism. In Question Answering tasks, BERT processes a given question and context to generate embeddings for each word, taking into account the entire context surrounding the words. The model then identifies the answer span within the context, effectively understanding and extracting relevant information. Fine-tuned for QA, BERT has demonstrated remarkable performance on various datasets and is widely adopted in applications such as search engines, virtual assistants, and information retrieval systems, enhancing the accuracy and efficiency of extracting precise answers from textual data.\n",
    "\n",
    "Python functions and data files to run this notebook are in my [Github](https://github.com/MehdiRezvandehy/Extractive-Question-Answering-using-BERT.git) page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#SQUAD-Data-Set\" data-toc-modified-id=\"SQUAD-Data-Set-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>SQUAD Data Set</a></span></li><li><span><a href=\"#Start-and-End-Index-of-Answer-within-Context\" data-toc-modified-id=\"Start-and-End-Index-of-Answer-within-Context-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Start and End Index of Answer within Context</a></span></li><li><span><a href=\"#Train-&amp;-Test-Split\" data-toc-modified-id=\"Train-&amp;-Test-Split-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Train &amp; Test Split</a></span></li><li><span><a href=\"#Freeze-BERT's-Parameters\" data-toc-modified-id=\"Freeze-BERT's-Parameters-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Freeze BERT's Parameters</a></span></li><li><span><a href=\"#Fine-tune\" data-toc-modified-id=\"Fine-tune-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Fine-tune</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test-Fine-tuned-Model\" data-toc-modified-id=\"Test-Fine-tuned-Model-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Test Fine-tuned Model</a></span></li></ul></li><li><span><a href=\"#Use-Huggingface-Fined-tuned-QA-Model\" data-toc-modified-id=\"Use-Huggingface-Fined-tuned-QA-Model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Use Huggingface Fined-tuned QA Model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, pipeline, \\\n",
    "                         DataCollatorWithPadding, TrainingArguments, Trainer, \\\n",
    "                         AutoModelForQuestionAnswering, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of answering: **Extractive**, **Abstractive**\n",
    "\n",
    "| **Extractive Answering** | **Abstractive Answering** |\n",
    "| --- | --- |\n",
    "| Answer to a question given a piece of text is a **direct substring** of the context  |  Answer to a question given a piece of context is a **free-form phrase** based on the context|\n",
    "|BERT  |  Decoder is required|\n",
    "|     |  GPT, T5|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can give a **question** and **some contexts**, then BERT can extract a subset of piece of context to answer that question. This is an extractive answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# We are using a large uncased BERT since we want to give a model a large data set since \n",
    "# question and asnwering has limited examples\n",
    "bert_tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased', return_token_type_ids=True)\n",
    "\n",
    "qa_bert = BertForQuestionAnswering.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQUAD Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQUAD 2.0 question and answering data set was downloaded from [kaggle](https://www.kaggle.com/datasets/parthplc/squad-20-csv-file). For this data set, there is **question** column which the answer is within column **context**. The columns **text** is the answer and **answer_start** gives the index that answer start within column **context**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86821, 3)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# load training data set\n",
    "df_qa = pd.read_csv('train-squad.csv')\n",
    "df_qa.rename({'text': 'answer'}, axis=1,inplace=True)\n",
    "\n",
    "df_qa = df_qa[['context','question','answer']]\n",
    "print(df_qa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".</td>\n",
       "      <td>What areas did Beyonce compete in when she was growing up?</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and become a solo singer?</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".   \n",
       "\n",
       "                                                           question  \\\n",
       "0                          When did Beyonce start becoming popular?   \n",
       "1        What areas did Beyonce compete in when she was growing up?   \n",
       "2  When did Beyonce leave Destiny's Child and become a solo singer?   \n",
       "\n",
       "                answer  \n",
       "0    in the late 1990s  \n",
       "1  singing and dancing  \n",
       "2                 2003  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qa[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start and End Index of Answer within Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_idx (big_index,small_index):\n",
    "    \"\"\"\n",
    "    Find the starting indices of a sequence of 'small_index' within 'big_index'.\n",
    "\n",
    "    Parameters:\n",
    "    - big_index (list): The larger sequence of indices.\n",
    "    - small_index (list): The smaller sequence of indices to be found within 'big_index'.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of starting indices where 'small_index' is found in 'big_index'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Iterate through each index in 'big_index'\n",
    "    for i in range(len(big_index)):\n",
    "        \n",
    "        # Initialize an empty list to store starting indices\n",
    "        indices = []\n",
    "        \n",
    "        # Check if the current index in 'big_index' matches the first index in 'small_index'\n",
    "        if big_index[i] == small_index[0]:\n",
    "            \n",
    "            # If there is a match, append the current index to 'indices'\n",
    "            indices.append(i)\n",
    "            \n",
    "            # If the length of 'small_index' is greater than 1, check for the entire sequence\n",
    "            if len(small_index)>1:\n",
    "                j = 1\n",
    "                \n",
    "                # Continue checking subsequent indices for a match with 'small_index'\n",
    "                while len(small_index)>j and big_index[i+j] == small_index[j]:\n",
    "                    indices.append(j+i)\n",
    "                    j += 1\n",
    "                    \n",
    "                     \n",
    "                if len(small_index) == j:\n",
    "                    return indices\n",
    "                    break\n",
    "            else:\n",
    "                return [i]\n",
    "                break\n",
    "\n",
    "def file_add(x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Tokenize the input question and context using BERT tokenizer and find the token indices\n",
    "    corresponding to the answer within the tokenized sequence.\n",
    "\n",
    "    Parameters:\n",
    "    - x (dict): Input dictionary containing 'question', 'context', and 'answer' keys.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the starting and ending token indices of the answer within the tokenized sequence.\n",
    "             If the answer is not found, it returns (-1, -1).\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Tokenize the question and context using BERT tokenizer\n",
    "    qst_contxt = bert_tokenizer.encode(x['question'],x['context'])\n",
    "    try:\n",
    "        # Tokenize the answer\n",
    "        answr = bert_tokenizer.encode(x['answer'])[1:-1]\n",
    "        \n",
    "        # Find the indices of the answer within the tokenized question and context\n",
    "        answr_idx = find_idx (qst_contxt,answr)\n",
    "        try:\n",
    "            # If multiple indices are found, use the first and last indices\n",
    "            if len(answr_idx)>1:\n",
    "                \n",
    "                # If only one index is found, use it for both start and end\n",
    "                tkn_strt,tkn_end = answr_idx[0], answr_idx[-1]\n",
    "            else :\n",
    "                tkn_strt,tkn_end = answr_idx[0], answr_idx[0]       \n",
    "        except TypeError: \n",
    "            \n",
    "            # Handle the case where answr_idx is not a list (Type Error)\n",
    "            tkn_strt,tkn_end = -1, -1\n",
    "            \n",
    "        # Return the starting and ending token indices of the answer    \n",
    "        return tkn_strt, tkn_end\n",
    "    \n",
    "    except TypeError:\n",
    "        \n",
    "        # Handle the case where answr is not properly defined (Type Error)\n",
    "        return -1, -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>start_positions</th>\n",
       "      <th>end_positions</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".</td>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was growing up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and become a solo singer?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           question  \\\n",
       "0                          When did Beyonce start becoming popular?   \n",
       "1        What areas did Beyonce compete in when she was growing up?   \n",
       "2  When did Beyonce leave Destiny's Child and become a solo singer?   \n",
       "3                     In what city and state did Beyonce  grow up?    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".   \n",
       "\n",
       "   start_positions  end_positions               answer  \n",
       "0               75             78    in the late 1990s  \n",
       "1               68             70  singing and dancing  \n",
       "2              143            143                 2003  \n",
       "3               58             60       Houston, Texas  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = df_qa.apply(lambda x: file_add(x), axis=1)\n",
    "df_qa['start_positions'], df_qa['end_positions'] = [i[0] for i in tmp], [i[1] for i in tmp]\n",
    "df_qa = df_qa[['question', 'context', 'start_positions', 'end_positions', 'answer']]\n",
    "df_qa[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qa.iloc[0]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the late 1990s'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 75, 76, 77 and 78 including question while encoding\n",
    "bert_tokenizer.decode(bert_tokenizer.encode(df_qa.iloc[0].question, df_qa.iloc[0].context)[75:79])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset.from_pandas` is a method provided by the deep learning framework `PyTorch`, specifically in the `torch.utils.data` module. This method is used to create a PyTorch dataset from a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test Split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only grab 8,000 examples because fine-tunning process is very expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset = Dataset.from_pandas(df_qa.sample(8000, random_state=32))\n",
    "\n",
    "# Dataset has a built in train test split method\n",
    "qa_dataset = qa_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'context', 'start_positions', 'end_positions', 'answer', '__index_level_0__'],\n",
       "        num_rows: 6400\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'context', 'start_positions', 'end_positions', 'answer', '__index_level_0__'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preprocessing here with truncation to truncate longer text\n",
    "def preprocess(data):\n",
    "    return bert_tokenizer(data['question'], data['context'], truncation=True) # anything pass window of 512\n",
    "                                                                              # should be truncated\n",
    "qa_dataset = qa_dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeze BERT's Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to speed up training, freeze all but the last 2 encoder layers in BERT \n",
    "for name, param in qa_bert.bert.named_parameters():\n",
    "    if 'encoder.layer.20' in name: # our large model has 24 encoder so everything until last 2 are removed\n",
    "        break\n",
    "    param.requires_grad = False  # disable training in BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic padding to speed up training\n",
    "data_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: question, context, __index_level_0__, answer. If question, context, __index_level_0__, answer are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1600\n",
      "  Batch size = 5\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [320/320 2:49:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 5.589837551116943,\n",
       " 'eval_runtime': 1452.9636,\n",
       " 'eval_samples_per_second': 1.101,\n",
       " 'eval_steps_per_second': 0.22}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "epochs = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./qsn_anw/results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    logging_dir='./qsn_anw/logs',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=qa_bert, # pretrained BERT\n",
    "    args=training_args,\n",
    "    train_dataset=qa_dataset['train'],\n",
    "    eval_dataset=qa_dataset['test'],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Get initial metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: question, context, __index_level_0__, answer. If question, context, __index_level_0__, answer are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 6400\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 5\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 5\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2560\n",
      "  Number of trainable parameters = 50386946\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2560' max='2560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2560/2560 8:31:56, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.126700</td>\n",
       "      <td>2.168481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.494200</td>\n",
       "      <td>2.071796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: question, context, __index_level_0__, answer. If question, context, __index_level_0__, answer are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1600\n",
      "  Batch size = 5\n",
      "Saving model checkpoint to ./qsn_anw/results\\checkpoint-1280\n",
      "Configuration saved in ./qsn_anw/results\\checkpoint-1280\\config.json\n",
      "Model weights saved in ./qsn_anw/results\\checkpoint-1280\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: question, context, __index_level_0__, answer. If question, context, __index_level_0__, answer are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1600\n",
      "  Batch size = 5\n",
      "Saving model checkpoint to ./qsn_anw/results\\checkpoint-2560\n",
      "Configuration saved in ./qsn_anw/results\\checkpoint-2560\\config.json\n",
      "Model weights saved in ./qsn_anw/results\\checkpoint-2560\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./qsn_anw/results\\checkpoint-2560 (score: 2.071795701980591).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2560, training_loss=2.3458202928304672, metrics={'train_runtime': 30721.6795, 'train_samples_per_second': 0.417, 'train_steps_per_second': 0.083, 'total_flos': 5815410818714640.0, 'train_loss': 2.3458202928304672, 'epoch': 2.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question and answering model is very large\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./qsn_anw/results\n",
      "Configuration saved in ./qsn_anw/results\\config.json\n",
      "Model weights saved in ./qsn_anw/results\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./qsn_anw/results\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./qsn_anw/results\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file ./qsn_anw/results\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./qsn_anw/results\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ./qsn_anw/results\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at ./qsn_anw/results.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"question-answering\", './qsn_anw/results', tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Fine-tuned Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.12055443972349167, 'start': 716, 'end': 724, 'answer': 'synapses'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"\"\"The brain is an organ that serves as the center of the nervous system in \n",
    "               all vertebrate and most invertebrate animals. Only a few invertebrates such as sponges, \n",
    "               jellyfish, adult sea squirts and starfish do not have a brain; diffuse or localised \n",
    "               nerve nets are present instead. The brain is located in the head, usually close to the \n",
    "               primary sensory organs for such senses as vision, hearing, balance, taste, and smell. \n",
    "               The brain is the most complex organ in a vertebrate's body. In a typical human, the \n",
    "               cerebral cortex (the largest part) is estimated to contain 15â€“33 billion neurons, \n",
    "               each connected by synapses to several thousand other neurons. These neurons communicate \n",
    "               with one another by means of long protoplasmic fibers called axons, which carry trains \n",
    "               of signal pulses called action potentials to distant parts of the brain or body targeting \n",
    "               specific recipient cells.\"\"\"\n",
    "\n",
    "pipe(\"How are neurons connected?\", txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer for question above is **synapses**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can google someone as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.18983420729637146, 'start': 278, 'end': 281, 'answer': 'PhD'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERSON = 'Mehdi Rezvandehy'\n",
    "\n",
    "# Note this is NOT an efficient way to search on google. This is done simply for education purposes\n",
    "google_html = BeautifulSoup(requests.get(f'https://www.google.com/search?q={PERSON}').text).get_text()[:512]\n",
    "\n",
    "pipe(f'Who is {PERSON}?', google_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Huggingface Fined-tuned QA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\mrezv/.cache\\huggingface\\hub\\models--bert-large-uncased-whole-word-masking-finetuned-squad\\snapshots\\cca7eb4efca266eff710a8c7154ecbc382b78e77\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased-whole-word-masking-finetuned-squad\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\mrezv/.cache\\huggingface\\hub\\models--bert-large-uncased-whole-word-masking-finetuned-squad\\snapshots\\cca7eb4efca266eff710a8c7154ecbc382b78e77\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased-whole-word-masking-finetuned-squad\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717a47b1b5e34874940a45a333eccb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at C:\\Users\\mrezv/.cache\\huggingface\\hub\\models--bert-large-uncased-whole-word-masking-finetuned-squad\\snapshots\\cca7eb4efca266eff710a8c7154ecbc382b78e77\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "loading configuration file config.json from cache at C:\\Users\\mrezv/.cache\\huggingface\\hub\\models--bert-large-uncased-whole-word-masking-finetuned-squad\\snapshots\\cca7eb4efca266eff710a8c7154ecbc382b78e77\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased-whole-word-masking-finetuned-squad\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\mrezv/.cache\\huggingface\\hub\\models--bert-large-uncased-whole-word-masking-finetuned-squad\\snapshots\\cca7eb4efca266eff710a8c7154ecbc382b78e77\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\mrezv/.cache\\huggingface\\hub\\models--bert-large-uncased-whole-word-masking-finetuned-squad\\snapshots\\cca7eb4efca266eff710a8c7154ecbc382b78e77\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\mrezv/.cache\\huggingface\\hub\\models--bert-large-uncased-whole-word-masking-finetuned-squad\\snapshots\\cca7eb4efca266eff710a8c7154ecbc382b78e77\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\mrezv/.cache\\huggingface\\hub\\models--bert-large-uncased-whole-word-masking-finetuned-squad\\snapshots\\cca7eb4efca266eff710a8c7154ecbc382b78e77\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased-whole-word-masking-finetuned-squad\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From Huggingface: https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad\n",
    "squad_pipe = pipeline(\"question-answering\", \"bert-large-uncased-whole-word-masking-finetuned-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9923588633537292, 'start': 15, 'end': 22, 'answer': 'Calgary'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_pipe(\"Where is Mehdi living these days?\", \"Mehdi lives in Calgary but Hamid lives in Edmonton.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 99% of correct score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question is: \n",
      "What two factors did Lee demonstrate intensified prejudice?\n",
      "\n",
      "\n",
      "context is: \n",
      "Scholars argue that Lee's approach to class and race was more complex \"than ascribing racial prejudice primarily to 'poor white trash' ... Lee demonstrates how issues of gender and class intensify prejudice, silence the voices that might challenge the existing order, and greatly complicate many Americans' conception of the causes of racism and segregation.\" Lee's use of the middle-class narrative voice is a literary device that allows an intimacy with the reader, regardless of class or cultural background, and fosters a sense of nostalgia. Sharing Scout and Jem's perspective, the reader is allowed to engage in relationships with the conservative antebellum Mrs. Dubose; the lower-class Ewells, and the Cunninghams who are equally poor but behave in vastly different ways; the wealthy but ostracized Mr. Dolphus Raymond; and Calpurnia and other members of the black community. The children internalize Atticus' admonition not to judge someone until they have walked around in that person's skin, gaining a greater understanding of people's motives and behavior.\n",
      "\n",
      "\n",
      "real answer is: \n",
      "gender and class\n",
      "\n",
      "\n",
      "Predict it with fine-tuned model \n",
      "{'score': 0.8647028207778931, 'start': 170, 'end': 186, 'answer': 'gender and class'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ir = 4000\n",
    "print (f'question is: \\n{df_qa.question.iloc[ir]}\\n\\n')\n",
    "print (f'context is: \\n{df_qa.context.iloc[ir]}\\n\\n')\n",
    "print (f'real answer is: \\n{df_qa.answer.iloc[ir]}\\n\\n')\n",
    "\n",
    "print (f'Predict it with fine-tuned model \\n{squad_pipe(df_qa.question.iloc[ir], df_qa.context.iloc[ir])}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.12055443972349167, 'start': 716, 'end': 724, 'answer': 'synapses'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"\"\"The brain is an organ that serves as the center of the nervous system in \n",
    "               all vertebrate and most invertebrate animals. Only a few invertebrates such as sponges, \n",
    "               jellyfish, adult sea squirts and starfish do not have a brain; diffuse or localised \n",
    "               nerve nets are present instead. The brain is located in the head, usually close to the \n",
    "               primary sensory organs for such senses as vision, hearing, balance, taste, and smell. \n",
    "               The brain is the most complex organ in a vertebrate's body. In a typical human, the \n",
    "               cerebral cortex (the largest part) is estimated to contain 15â€“33 billion neurons, \n",
    "               each connected by synapses to several thousand other neurons. These neurons communicate \n",
    "               with one another by means of long protoplasmic fibers called axons, which carry trains \n",
    "               of signal pulses called action potentials to distant parts of the brain or body targeting \n",
    "               specific recipient cells.\"\"\"\n",
    "\n",
    "pipe(\"How are neurons connected?\", txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question is: \n",
      "How are neurons connected\n",
      "\n",
      "\n",
      "context is: \n",
      "The brain is an organ that serves as the center of the nervous system in \n",
      "               all vertebrate and most invertebrate animals. Only a few invertebrates such as sponges, \n",
      "               jellyfish, adult sea squirts and starfish do not have a brain; diffuse or localised \n",
      "               nerve nets are present instead. The brain is located in the head, usually close to the \n",
      "               primary sensory organs for such senses as vision, hearing, balance, taste, and smell. \n",
      "               The brain is the most complex organ in a vertebrate's body. In a typical human, the \n",
      "               cerebral cortex (the largest part) is estimated to contain 15â€“33 billion neurons, \n",
      "               each connected by synapses to several thousand other neurons. These neurons communicate \n",
      "               with one another by means of long protoplasmic fibers called axons, which carry trains \n",
      "               of signal pulses called action potentials to distant parts of the brain or body targeting \n",
      "               specific recipient cells.\n",
      "\n",
      "\n",
      "real answer is: \n",
      "synapses\n",
      "\n",
      "\n",
      "Predict it with fine-tuned model \n",
      "{'score': 0.3291873335838318, 'start': 713, 'end': 724, 'answer': 'by synapses'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ir = 4000\n",
    "print (f'question is: \\nHow are neurons connected\\n\\n')\n",
    "print (f'context is: \\n{txt}\\n\\n')\n",
    "print (f'real answer is: \\nsynapses\\n\\n')\n",
    "\n",
    "print (f'Predict it with fine-tuned model \\n{squad_pipe(\"How are neurons connected?\", txt)}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "605.8px",
    "left": "1380px",
    "top": "46.8px",
    "width": "296.662px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
